**Practica 4 - Back Propagation**
Entrenar un aproximador para la función Xor usando 2 capas intermedias.
* Usar 2 neuronas en la capa anterior a la salida(segunda capa oculta)
* Usar al menos 2(pueden ser más) en la  primera capa oculta.
* Usar activación ReLu en las capas intermedias y  no activación en la salida
Usar numpy.
* Realizar 5 experimentos, en cada experimento(corrida de entrenamiento):
* Inicializar los parámetros aleatoriamente con distribución normal centrada en 0 y std = 0.1
* Retornar la representación intermedia de la segunda capa oculta.
* Graficar las 5 representaciones intermedias(1 por experimento), comparar, comentar y/o concluir.
